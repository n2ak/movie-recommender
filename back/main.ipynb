{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from filldb import read_df\n",
    "import warnings\n",
    "import torch.utils.data\n",
    "from model import MF, MFParams\n",
    "from filldb import read_df\n",
    "from train import create_target_matrix, set_seed, DL\n",
    "from ncf import NCF, NCFParams, default_ncf\n",
    "from train import train2, compute_f1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,ratings):\n",
    "    movieIds = [1,30,177,10]\n",
    "    userIds = [1,]*len(movieIds)\n",
    "#     _userIds = torch.repeat_interleave(torch.tensor(userIds), len(movieIds)).tolist()\n",
    "\n",
    "    pred = model.predict(userIds,movieIds)\n",
    "    pred = (pred*2).round()/2\n",
    "    df = pd.DataFrame({\"userId\":userIds ,\"movieId\": movieIds, \"pred_rating\": pred.flatten().tolist()})\n",
    "\n",
    "    df = df.merge(ratings.loc[ratings.userId.isin(userIds)].loc[ratings.movieId.isin(movieIds)][[\"movieId\",\"rating\",\"userId\"]],\n",
    "            on=[\"userId\",\"movieId\"],how=\"outer\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import main,plot\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "losses, f1, val_losses, val_f1 = main(\n",
    "    500,\n",
    "    train_df,\n",
    "    \"models/ncf1.pt\",\n",
    "    load_model=True\n",
    ")\n",
    "plot(losses, f1, val_losses, val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_of_every_user(df):\n",
    "    indices = []\n",
    "    rows = []\n",
    "    for i in range(df.userId.nunique()):\n",
    "        row = df.loc[df.userId == i]\n",
    "        indices.append(row.index[0])\n",
    "        rows.append(row.iloc[0])\n",
    "    df = df.drop(indices,axis=0)\n",
    "    return df,pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 1337\n",
    "\n",
    "def load(split=None):\n",
    "    ratings = read_df(\"\", 200000)[[\"userId\",\"movieId\",\"rating\"]]#.sample(frac=1)\n",
    "    nu, nm = ratings.userId.nunique(), ratings.movieId.nunique()\n",
    "    if split is not None:\n",
    "        dfs = get_first_of_every_user(ratings)\n",
    "        # s = int(ratings.shape[0]*0.8)\n",
    "        # dfs = ratings.iloc[:s], ratings.iloc[s:]\n",
    "    else:\n",
    "        dfs = [ratings]\n",
    "    dfs = [\n",
    "        (torch.from_numpy(df.userId.values).long(),\n",
    "        torch.from_numpy(df.movieId.values).long(),\n",
    "        torch.from_numpy(df.rating.values).float())\n",
    "        for df in dfs\n",
    "    ]\n",
    "    del ratings\n",
    "    return nu,nm,dfs\n",
    "nu, nm,(df1,df2) = load(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DL(*df1, 0x1000*2,shuffle=True)\n",
    "val_dl = DL(*df2, 0x100,shuffle=False)\n",
    "params = Params(\n",
    "    nu, \n",
    "    nm,\n",
    "    0.001,\n",
    "    32,\n",
    "    use_bias=True,\n",
    "    usePQ=False\n",
    ")\n",
    "def loss_fn(pred, real, embedings, usePQ=False):\n",
    "    return F.mse_loss(pred,real)\n",
    "    l = F.l1_loss(pred, real)\n",
    "    if not usePQ:\n",
    "        return l\n",
    "    P, Q, ub, mb = embedings\n",
    "    return l + .01 * (\n",
    "        torch.norm(Q, p=\"fro\")+torch.norm(P, p=\"fro\") +\n",
    "        (ub**2).mean() + (mb**2).mean()\n",
    "    )\n",
    "model = MF(params,seed=seed).to(device)\n",
    "last_state = {}\n",
    "scheduler = None\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=params.lr,weight_decay=.0001)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=20,cooldown=20,min_lr=.00001)\n",
    "losses, f1, val_losses, val_f1 = train2(\n",
    "    model, optimizer, train_dl, loss_fn, lambda a,b,*_:compute_f1(a,b,None),\n",
    "    500, device, scheduler=scheduler, val_ld=val_dl,\n",
    "    last_state=last_state)\n",
    "plot(losses, f1,val_losses,val_f1)\n",
    "model.save(\"models/mf.pt\", optimizer=optimizer,\n",
    "         losses=losses, f1=f1,val_losses=val_losses,val_f1=val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = ratings.pivot(index=\"userId\",columns=\"movieId\",values=\"rating\").fillna(0)\n",
    "nu,nm = matrix.shape\n",
    "\n",
    "def loss_fn(pred, real, embedings,_):\n",
    "    return F.mse_loss(pred, real)\n",
    "load_model = False\n",
    "set_seed(seed)\n",
    "if not load_model:\n",
    "    ncf, ncf_opt, last_state = default_ncf(nu,nm,device)\n",
    "else:\n",
    "    ncf, ncf_opt, last_state = NCF.load(\n",
    "        \"models/ncf.pt\",optCls=torch.optim.AdamW)\n",
    "scheduler = None\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(ncf_opt, 'min',patience=50,cooldown=50,min_lr=.00001)\n",
    "val_dl = DL(*df2, 0x100, shuffle=False)\n",
    "def train_dl(ubs,mbs):\n",
    "    for i in range (0,nu,ubs):\n",
    "        u_ids = torch.arange(i,i+ubs)\n",
    "        for j in range (0,nm,mbs):\n",
    "            m_ids = torch.arange(j,j+mbs)\n",
    "            ratings = matrix.iloc[u_ids.tolist(), m_ids.tolist()]\n",
    "            ratings = torch.from_numpy(ratings.values)\n",
    "            yield u_ids,m_ids,ratings\n",
    "train_dl = DL(*df1, 0x1000*2,shuffle=True)\n",
    "losses, f1, val_losses, val_f1 = train2(\n",
    "    ncf, ncf_opt, train_dl, loss_fn, lambda a,b,*_:compute_f1(a,b,None),\n",
    "    500, device, scheduler=scheduler, val_ld=val_dl,\n",
    "    last_state=last_state)\n",
    "plot(losses, f1, val_losses,val_f1)\n",
    "ncf.save(\"models/ncf.pt\", optimizer=ncf_opt,\n",
    "         losses=losses,f1=f1,val_losses=val_losses,val_f1=val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geturls import load_df,url\n",
    "covers_path = \"covers.csv\"\n",
    "df = load_df(covers_path, s=10000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "possible_classes = [\"sc-491663c0-7 dUfBfF\", \"sc-491663c0-7 jmhiib\"]\n",
    "def get(i, id):\n",
    "    err = -1\n",
    "    try:\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        u = url(id)\n",
    "        resp = requests.get(u, headers={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36\"\n",
    "        }, timeout=10)\n",
    "        if resp.status_code != 200:\n",
    "            # print(resp.content.decode())\n",
    "            return (id, err)\n",
    "        soup = BeautifulSoup(resp.content.decode(), \"html.parser\")\n",
    "        err = -2\n",
    "        div = None\n",
    "        for c in possible_classes:\n",
    "            divs = soup.find_all(\"div\", {\n",
    "                \"class\": c\n",
    "            })\n",
    "            if len(divs)==0:\n",
    "                continue\n",
    "            div = divs[0]\n",
    "        if div is None:\n",
    "            raise \"\"\n",
    "        err = -3\n",
    "        [img] = div.findAll(\"img\")\n",
    "        err = -4\n",
    "        return id, img[\"src\"]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return (id, err)\n",
    "imdb = 125877\n",
    "get(0, imdb),url(imdb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
